{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Using LLMs\n",
    "\n",
    "This Jupyter Notebook demonstrates the use of various Large Language Model (LLM) providers and tools for natural language processing tasks. It showcases how to interact with LLMs using the `crewai` library (which is used by Agentics), parse structured outputs with Pydantic models, and explore available LLM connections. The notebook provides practical examples for calling different LLMs, formatting responses, and integrating with external providers such as OpenAI and IBM WatsonX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62180815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.9 environment at: /Users/gliozzo/Code/agentics911/agentics/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 64ms\u001b[0m\u001b[0m\n",
      "In Colab: False\n"
     ]
    }
   ],
   "source": [
    "! uv pip install agentics-py\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "CURRENT_PATH = \"\"\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(\"In Colab:\", IN_COLAB)\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    CURRENT_PATH = \"/content/drive/MyDrive/\"\n",
    "    # Mount your google drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    from google.colab import userdata\n",
    "\n",
    "    os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")\n",
    "else:\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your GEMINI_API_KEY:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Connect to your own LLM provider\n",
    "Agentics uses CrewAI wrappers for main LLM providers. You can initialize your LLM as follows.\n",
    "[find out more](https://docs.crewai.com/en/concepts/llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec92f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<crewai.llm.LLM object at 0x109417dd0>\n"
     ]
    }
   ],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "# pick a provider (openai, anthropic, groq, etc.) - see crewai docs for details\n",
    "llm = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    "    temperature=0.7,  # Adjust based on task\n",
    "    max_tokens=4096,  # Set based on output needs\n",
    "    timeout=300,\n",
    ")  # Longer timeout for complex tasks\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Perform Simple LLM call\n",
    "\n",
    "Once an LLM is instatiated, you can perform LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab039e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is located in **Paris, France**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.call(\"where is the Eiffel Tower?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Perform Structured Call\n",
    "\n",
    "LLMs can generate structured objects given a pydantic schema if you instantiate them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984913a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"short_answer\": \"The sky is blue because of a phenomenon called Rayleigh scattering.\",\n",
      "  \"detailed_answer\": \"Sunlight is made up of all the colors of the rainbow. When sunlight enters the Earth's atmosphere, it collides with tiny air molecules. This causes the light to scatter in different directions. Blue and violet light have shorter wavelengths, and are scattered more than other colors, such as red and orange. Because blue light is scattered the most, it reaches our eyes from all directions, making the sky appear blue. Violet light is scattered even more, but our eyes are less sensitive to violet, and the sun emits less violet light, so the sky appears blue instead of violet. At sunrise and sunset, the sunlight has to travel through more of the atmosphere to reach us. This means that more of the blue light is scattered away, leaving the red and orange light to dominate, which is why sunsets are often red and orange.\",\n",
      "  \"confidence\": 0.95\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    short_answer: str\n",
    "    detailed_answer: str\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "struct_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=Answer)\n",
    "\n",
    "print(struct_llm.call(\"Why is the sky blue?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## You can also use structured decoding for information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8c2ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"books\": [\n",
      "    {\n",
      "      \"title\": \"Tractatus Logico-Philosophicus\",\n",
      "      \"publisher\": \"Routledge and Kegan Paul\",\n",
      "      \"year\": 1961,\n",
      "      \"author\": {\n",
      "        \"name\": \"Ludwig Wittgenstein\",\n",
      "        \"city\": \"Vienna\",\n",
      "        \"occupation\": \"Philosopher\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Philosophical Investigations\",\n",
      "      \"publisher\": \"Basil Blackwell\",\n",
      "      \"year\": 1963,\n",
      "      \"author\": {\n",
      "        \"name\": \"Ludwig Wittgenstein\",\n",
      "        \"city\": \"Vienna\",\n",
      "        \"occupation\": \"Philosopher\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Wittgenstein on Rules and Private Language\",\n",
      "      \"publisher\": \"Harvard University Press\",\n",
      "      \"year\": 1982,\n",
      "      \"author\": {\n",
      "        \"name\": \"Saul A. Kripke\",\n",
      "        \"city\": \"New York\",\n",
      "        \"occupation\": \"Philosopher\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"people\": [\n",
      "    {\n",
      "      \"name\": \"Ludwig Wittgenstein\",\n",
      "      \"city\": \"Vienna\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Bertrand Russell\",\n",
      "      \"city\": \"Cambridge\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Gottlob Frege\",\n",
      "      \"city\": \"Wismar\",\n",
      "      \"occupation\": \"Mathematician, Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Arthur Schopenhauer\",\n",
      "      \"city\": \"Gdańsk\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    city: str\n",
    "    occupation: str\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    publisher: str\n",
    "    year: int\n",
    "    author: Person\n",
    "\n",
    "\n",
    "class InformationExtraction(BaseModel):\n",
    "    books: list[Book]\n",
    "    people: list[Person]\n",
    "\n",
    "\n",
    "person_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=InformationExtraction)\n",
    "print(person_llm.call(requests.get(\"https://iep.utm.edu/wittgens/\").text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Using Agentics Predefined LLMs\n",
    "\n",
    "Agentics has the following LLM handles: watsonx_llm, openai_llm, gemini_llm\n",
    "You can directly import and use them as defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b95374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'watsonx': <crewai.llm.LLM object at 0x14d4f3800>, 'gemini': <crewai.llm.LLM object at 0x14d24b890>, 'openai': <crewai.llm.LLM object at 0x14d4683b0>}\n",
      "Rome is the capital city of Italy. It lies in the central‑western part of the Italian Peninsula, on the banks of the Tiber River. Geographically, its coordinates are approximately **41.90° N latitude and 12.48° E longitude**. The city is situated in the region of **Lazio**, about 24 km (15 mi) inland from the Tyrrhenian Sea.\n",
      "Rome is the capital city of **Italy**. It is located in the central-western portion of the Italian Peninsula, along the Tiber River.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agentics import AG\n",
    "\n",
    "print(AG.get_llm_provider(\"list\"))\n",
    "\n",
    "llm = AG.get_llm_provider()  ## get the default LLM provider from the available ones\n",
    "print(llm.call(\"Where is Rome?\"))\n",
    "\n",
    "llm = AG.get_llm_provider(\n",
    "    \"gemini\"\n",
    ")  ## get a specific LLM provider from the available ones,change \"gemini\" with \"openai\", \"watsonx\", etc. as needed\n",
    "print(llm.call(\"Where is Rome?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Play with different data models on your favourite domain (e.g. stocks) providing relevant data. Enjoy tructured decoding magic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
